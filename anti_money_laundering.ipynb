{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skalwalker/AntiMoneyLaundering/blob/main/anti_money_laundering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubxiWav99sa1"
      },
      "source": [
        "# IBM Transactions for Anti Money Laundering\n",
        "\n",
        "The project is based on the analysis of the «IBM Transactions for Anti Money Laundering» dataset published on [Kaggle](https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml) and released under the Community Data License Agreement – Sharing – Version 1.0. This dataset contains several CSV files, each having a different combination of data size and amount of illicit transactions.\n",
        "\n",
        "## About\n",
        "\n",
        "This project is a partial requisite for completing the courses of \"Algorithms for massive datasets\" and \"Statistical methods for ML\" on the masters degree computer science program from Università degli Studi di Milano.\n",
        "\n",
        "- **Author:** Renato Avellar Nobre\n",
        "- **Matriculation Number:** 984405\n",
        "- **Exam Project Year:** 22/23\n",
        "\n",
        "### Disclaimer\n",
        "\n",
        "\"I declare that this material, which I now submit for assessment, is entirely my own work and has not been taken from the work of others, save and to the extent that such work has been cited and acknowledged within the text of my work. I understand that plagiarism, collusion, and copying are grave and serious offences in the university and accept the penalties that would be imposed should I engage in plagiarism, collusion or copying. This assignment, or any part of it, has not been previously submitted by me or any other person for assessment on this or any other course of study.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL6OQSo_Ai65"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The task is to implement a system which predicts whether or not a transaction is illicit, using the attribute \"Is Laundering\" as a label to be predicted. Classification should be done exploiting a random forest, organizing the project as follows.\n",
        "\n",
        "1. A sequential implementation (from scratch) of the learning algorithm for a decision tree should be provided, and tested using one or more subsets of the dataset which can be loaded in main memory.\n",
        "\n",
        "2. A mock-up code that uses spark in order to consider a dataset and processes it in order to distribute the creation of the single trees in a random forest should be proposed. In particular, the construction of each tree should be done by providing different data to each worker, both subsampling the number of rows (i.e., labeled objects) and columns (i.e., attributes) in the overall dataset. Concerning the first kind of subsampling, you might possibly consider introducing the so-called bootstrap sampling, in which the labeled objects are sampled with replacement and therefore a same object can occur more than once in the resulting dataset. It is not required to distribute the creation of a single decision tree: for this task you are free to use the implementation provided in point 1, as well as the implementation already available in scikit-learn.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvV088qACMaw"
      },
      "source": [
        "## Before we start...\n",
        "\n",
        "Please upload the JSON file of your Kaggle API by executing the code below. Kaggle API JSON files can be generated on your [Kaggle user profile setting](https://www.kaggle.com/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "5aA2qb0ICLtZ",
        "outputId": "047c6f4d-8264-427a-d713-f9407952f0ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-394dd929-b1c4-44ff-a809-e5591e584347\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-394dd929-b1c4-44ff-a809-e5591e584347\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGnDQYvLB3rF"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YrUoObNGILG",
        "outputId": "f0526842-7cc5-428f-9441-7086d4ade16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directories created successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_folders = [\"01_raw\"]\n",
        "\n",
        "try:\n",
        "    os.makedirs(\"data\", exist_ok = True)\n",
        "    [os.makedirs(\"data/\" + folder_name, exist_ok = True) for folder_name in data_folders]\n",
        "    print(\"Directories created successfully\")\n",
        "except OSError as error:\n",
        "    print(f\"Directories can not be created: {error}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp_-mZuN5z2o"
      },
      "source": [
        "## Fetching Files from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z-WsFbK9BMU",
        "outputId": "636f596c-94f0-4e85-a090-4725a0ef38ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ibm-transactions-for-anti-money-laundering-aml.zip to /content\n",
            "100% 7.42G/7.42G [01:40<00:00, 116MB/s]\n",
            "100% 7.42G/7.42G [01:40<00:00, 79.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ealtman2019/ibm-transactions-for-anti-money-laundering-aml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSb8QvE59Zk_",
        "outputId": "d922ad41-89e9-43de-bf77-52f9a8c8b211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ibm-transactions-for-anti-money-laundering-aml.zip\n",
            "  inflating: ./data/01_raw/HI-Large_Patterns.txt  \n",
            "  inflating: ./data/01_raw/HI-Large_Trans.csv  \n",
            "  inflating: ./data/01_raw/HI-Medium_Patterns.txt  \n",
            "  inflating: ./data/01_raw/HI-Medium_Trans.csv  \n",
            "  inflating: ./data/01_raw/HI-Small_Patterns.txt  \n",
            "  inflating: ./data/01_raw/HI-Small_Trans.csv  \n",
            "  inflating: ./data/01_raw/LI-Large_Patterns.txt  \n",
            "  inflating: ./data/01_raw/LI-Large_Trans.csv  \n",
            "  inflating: ./data/01_raw/LI-Medium_Patterns.txt  \n",
            "  inflating: ./data/01_raw/LI-Medium_Trans.csv  \n",
            "  inflating: ./data/01_raw/LI-Small_Patterns.txt  \n",
            "  inflating: ./data/01_raw/LI-Small_Trans.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip ibm-transactions-for-anti-money-laundering-aml.zip -d ./data/01_raw/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgow9c9nH0lN"
      },
      "outputs": [],
      "source": [
        "!rm ibm-transactions-for-anti-money-laundering-aml.zip\n",
        "!rm ./data/01_raw/*.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hszm7Ijy4VC1"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z75NmbV24qv1",
        "outputId": "1e143dc1-2727-4a59-900a-937a0500569f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.23.3-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.3.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.5.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.1)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.7.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Installing collected packages: jedi, comm, ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.23.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.1.3 ipykernel-6.23.3 jedi-0.18.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=80b541e35506c5d421b352d20b828b582b59fa4a8a250ea84dd238990aaa956c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade ipykernel\n",
        "!pip install kaggle\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU5_kZqazZVT"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn7TuiLM4HDH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvBpD42vCK-R"
      },
      "source": [
        "## Setting Up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb2XfyiCCOCr"
      },
      "outputs": [],
      "source": [
        "spark = None\n",
        "if spark:\n",
        "  spark.stop()\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "          .appName(\"MoneyLaundering\") \\\n",
        "          .config(\"spark.executor.memory\", \"2g\") \\\n",
        "          .config(\"spark.executor.cores\", \"5\") \\\n",
        "          .config(\"spark.driver.memory\", \"3g\") \\\n",
        "          .config(\"spark.executor.instances\", \"4\") \\\n",
        "          .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
        "          .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7joBfAxtSOyk",
        "outputId": "a1320058-bbd2-4d5a-dbb0-590913982655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark executor memory: 2g\n",
            "Spark app submittime: 1687797598217\n",
            "Spark executor instances: 4\n",
            "Spark executor cores: 5\n",
            "Spark app name: MoneyLaundering\n",
            "Spark driver port: 40251\n",
            "Spark executor id: driver\n",
            "Spark sql shuffle partitions: 16\n",
            "Spark driver extrajavaoptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
            "Spark driver memory: 3g\n",
            "Spark rdd compress: True\n",
            "Spark app starttime: 1687797598713\n",
            "Spark serializer objectstreamreset: 100\n",
            "Spark master: local[*]\n",
            "Spark submit pyfiles: \n",
            "Spark submit deploymode: client\n",
            "Spark app id: local-1687797603489\n",
            "Spark driver host: 17ee6595c7d4\n",
            "Spark ui showconsoleprogress: true\n",
            "Spark executor extrajavaoptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n"
          ]
        }
      ],
      "source": [
        "for x in spark.sparkContext.getConf().getAll():\n",
        "  print(f\"{x[0].replace('.', ' ').capitalize()}: {x[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nccoQ3Q4PBnx"
      },
      "source": [
        "# 0. Data Engineering Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiZjjDhWJaQX",
        "outputId": "d5093990-8cc1-4a52-876f-94c1db22f9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 41GB\n",
            "-rw-r--r-- 1 root root 18GB Feb 28 11:54 HI-Large_Trans.csv\n",
            "-rw-r--r-- 1 root root  4GB Feb 28 12:08 HI-Medium_Trans.csv\n",
            "-rw-r--r-- 1 root root  1GB Feb 28 12:12 HI-Small_Trans.csv\n",
            "-rw-r--r-- 1 root root 17GB Feb 28 12:12 LI-Large_Trans.csv\n",
            "-rw-r--r-- 1 root root  3GB Feb 28 12:28 LI-Medium_Trans.csv\n",
            "-rw-r--r-- 1 root root  1GB Feb 28 12:31 LI-Small_Trans.csv\n"
          ]
        }
      ],
      "source": [
        "!ls -l --block-size=GB ./data/01_raw/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNcVyLXtbWWM"
      },
      "source": [
        "## Raw Data\n",
        "\n",
        "The raw layer is the starting point of the data pipeline and includes the sourced data model(s) that should never be altered. It serves as the single source of truth for all subsequent work. Typically, these data models are untyped, such as CSV files.\n",
        "\n",
        "* We never mutate the data here, only work on copies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QifwN0RPJtd"
      },
      "outputs": [],
      "source": [
        "# High Ilicity Datasets\n",
        "hi_small_df = spark.read.csv(\"./data/01_raw/HI-Small_Trans.csv\", header=True)\n",
        "hi_large_df = spark.read.csv(\"./data/01_raw/HI-Large_Trans.csv\", header=True)\n",
        "\n",
        "# Low Ilicity Datasets\n",
        "li_small_df = spark.read.csv(\"./data/01_raw/LI-Small_Trans.csv\", header=True)\n",
        "li_large_df = spark.read.csv(\"./data/01_raw/LI-Large_Trans.csv\", header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf2WhWPDGepz",
        "outputId": "6c827659-83b8-4bfc-d456-5056fd8dc207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Timestamp: string (nullable = true)\n",
            " |-- From Bank: string (nullable = true)\n",
            " |-- Account2: string (nullable = true)\n",
            " |-- To Bank: string (nullable = true)\n",
            " |-- Account4: string (nullable = true)\n",
            " |-- Amount Received: string (nullable = true)\n",
            " |-- Receiving Currency: string (nullable = true)\n",
            " |-- Amount Paid: string (nullable = true)\n",
            " |-- Payment Currency: string (nullable = true)\n",
            " |-- Payment Format: string (nullable = true)\n",
            " |-- Is Laundering: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hi_small_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNk_XM1JGtIO",
        "outputId": "28021763-4ddb-4bc0-e7ae-2a98c4420209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are all HI cols the same? True\n",
            "Are all LI cols the same? True\n",
            "Are LI cols the same in HI? True\n"
          ]
        }
      ],
      "source": [
        "# Verify if all columns are equal\n",
        "hi_cols_equal = (hi_small_df.columns == hi_large_df.columns)\n",
        "li_cols_equal = (li_large_df.columns == li_small_df.columns)\n",
        "\n",
        "print(f\"Are all HI cols the same? {hi_cols_equal}\")\n",
        "print(f\"Are all LI cols the same? {li_cols_equal}\")\n",
        "print(f\"Are LI cols the same in HI? {hi_cols_equal == li_cols_equal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9-Nxt9SMPCP",
        "outputId": "211058f7-4409-45fb-ecb8-046feed18301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|       Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|2022/09/01 00:20|      010|8000EBD30|    010|8000EBD30|        3697.34|         US Dollar|    3697.34|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:20|    03208|8000F4580|    001|8000F5340|           0.01|         US Dollar|       0.01|       US Dollar|        Cheque|            0|\n",
            "|2022/09/01 00:00|    03209|8000F4670|  03209|8000F4670|       14675.57|         US Dollar|   14675.57|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:02|      012|8000F5030|    012|8000F5030|        2806.97|         US Dollar|    2806.97|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:06|      010|8000F5200|    010|8000F5200|       36682.97|         US Dollar|   36682.97|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:03|      001|8000F5AD0|    001|8000F5AD0|        6162.44|         US Dollar|    6162.44|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:08|      001|8000EBAC0|    001|8000EBAC0|          14.26|         US Dollar|      14.26|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:16|      001|8000EC1E0|    001|8000EC1E0|          11.86|         US Dollar|      11.86|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:26|      012|8000EC280| 002439|8017BF800|           7.66|         US Dollar|       7.66|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:21|      001|8000EDEC0|0211050|80AEF5310|         383.71|         US Dollar|     383.71|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:04|      001|8000F4510| 011813|8011305D0|           9.82|         US Dollar|       9.82|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:04|      001|8000F47F0|    001|8000F47F0|           9.38|         US Dollar|       9.38|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:08|      001|8000F4FE0|0245335|812ED62E0|           4.01|         US Dollar|       4.01|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:17|      010|80012FD90|0036056|812ED6380|         106.70|         US Dollar|     106.70|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:11|      012|80012FE00| 013037|805B34210|           0.54|         US Dollar|       0.54|       US Dollar|   Credit Card|            0|\n",
            "|2022/09/01 00:09|      001|80012FE50|    001|80012FE50|     3944232.29|         US Dollar| 3944232.29|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:11|      010|80012FEA0|    010|80012FEA0|       10020.68|         US Dollar|   10020.68|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:00|    01420|8005DFEB0|  01420|8005DFEB0|         897.37|         US Dollar|     897.37|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:28|    01665|8005E18F0|  01665|8005E18F0|         157.57|         US Dollar|     157.57|       US Dollar|  Reinvestment|            0|\n",
            "|2022/09/01 00:22|    01665|8005E24C0|  01665|8005E24C0|          52.75|         US Dollar|      52.75|       US Dollar|  Reinvestment|            0|\n",
            "+----------------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hi_small_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV78SInWS4Iy",
        "outputId": "1c20a3e5-8a45-4637-f374-565cc0e2da15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank|Account2|To Bank|Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|        0|        0|       0|      0|       0|              0|                 0|          0|               0|             0|            0|\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "null_counts = hi_small_df.select([sum(col(column).isNull().cast(\"integer\")).alias(column) for column in hi_small_df.columns])\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r06Dq3S7baMU"
      },
      "source": [
        "## Intermediate Data\n",
        "\n",
        "In practice the intermediate layer only needs to be a typed mirror of the raw layer still within the ‘source’ data model\n",
        "\n",
        "* Once the intermediate layer exists, you never have to touch the raw layer and we eliminate the risks associated with mutating the original data.\n",
        "\n",
        "* Profiling, EDA and any data quality assessments should be performed at this point.\n",
        "\n",
        "* Cleaning column names, parsing dates and dropping completely null columns are other ‘transformations’ commonly performed at this stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-lnxr6FP0cw"
      },
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField(\"Timestamp\", StringType(), nullable=False),\n",
        "    StructField(\"From Bank\", IntegerType(), nullable=False),\n",
        "    StructField(\"Account2\", StringType(), nullable=False),\n",
        "    StructField(\"To Bank\", IntegerType(), nullable=False),\n",
        "    StructField(\"Account4\", StringType(), nullable=False),\n",
        "    StructField(\"Amount Received\", FloatType(), nullable=False),\n",
        "    StructField(\"Receiving Currency\", StringType(), nullable=False),\n",
        "    StructField(\"Amount Paid\", FloatType(), nullable=False),\n",
        "    StructField(\"Payment Currency\", StringType(), nullable=False),\n",
        "    StructField(\"Payment Format\", StringType(), nullable=False),\n",
        "    StructField(\"Is Laundering\", IntegerType(), nullable=False),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wdznlpfMf28"
      },
      "outputs": [],
      "source": [
        "hi_small_df = spark.read.csv(\"./data/01_raw/HI-Small_Trans.csv\", header=True, schema=schema)\n",
        "hi_large_df = spark.read.csv(\"./data/01_raw/HI-Large_Trans.csv\", header=True, schema=schema)\n",
        "li_small_df = spark.read.csv(\"./data/01_raw/LI-Small_Trans.csv\", header=True, schema=schema)\n",
        "li_large_df = spark.read.csv(\"./data/01_raw/LI-Large_Trans.csv\", header=True, schema=schema)\n",
        "\n",
        "# Fixing Timestamp\n",
        "def fix_timestamp(df):\n",
        "  format = \"yyyy/MM/dd HH:mm\"\n",
        "  df = df.withColumn(\"Timestamp2\",to_timestamp(\"Timestamp\", format=format).cast('timestamp'))\n",
        "  df = df.drop(\"Timestamp\")\n",
        "  df = df.withColumnRenamed(\"Timestamp2\", \"Timestamp\")\n",
        "  return df\n",
        "\n",
        "hi_small_df = fix_timestamp(hi_small_df)\n",
        "hi_large_df = fix_timestamp(hi_large_df)\n",
        "li_small_df = fix_timestamp(li_small_df)\n",
        "li_large_df = fix_timestamp(li_large_df)\n",
        "\n",
        "# hi_medium_df = spark.read.csv(\"./data/01_raw/HI-Medium_Trans.csv\", header=True, schema=schema)\n",
        "# li_medium_df = spark.read.csv(\"./data/01_raw/LI-Medium_Trans.csv\", header=True, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqLHkGFWhQmW",
        "outputId": "97b7a846-3181-4e71-ee15-12cef13fd7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- From Bank: integer (nullable = true)\n",
            " |-- Account2: string (nullable = true)\n",
            " |-- To Bank: integer (nullable = true)\n",
            " |-- Account4: string (nullable = true)\n",
            " |-- Amount Received: float (nullable = true)\n",
            " |-- Receiving Currency: string (nullable = true)\n",
            " |-- Amount Paid: float (nullable = true)\n",
            " |-- Payment Currency: string (nullable = true)\n",
            " |-- Payment Format: string (nullable = true)\n",
            " |-- Is Laundering: integer (nullable = true)\n",
            " |-- Timestamp: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "li_small_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbSid4mwm2eZ",
        "outputId": "54056981-0c9f-4afe-c28b-7e128e1491c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|          Timestamp|\n",
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "|       11|8000ECA90|     11|8000ECA90|      3195403.0|         US Dollar|  3195403.0|       US Dollar|  Reinvestment|            0|2022-09-01 00:08:00|\n",
            "|     3402|80021DAD0|   3402|80021DAD0|        1858.96|         US Dollar|    1858.96|       US Dollar|  Reinvestment|            0|2022-09-01 00:21:00|\n",
            "|       11|8000ECA90|   1120|8006AA910|       592571.0|         US Dollar|   592571.0|       US Dollar|        Cheque|            0|2022-09-01 00:00:00|\n",
            "|     3814|8006AD080|   3814|8006AD080|          12.32|         US Dollar|      12.32|       US Dollar|  Reinvestment|            0|2022-09-01 00:16:00|\n",
            "|       20|8006AD530|     20|8006AD530|        2941.56|         US Dollar|    2941.56|       US Dollar|  Reinvestment|            0|2022-09-01 00:00:00|\n",
            "|       12|8006ADD30|     12|8006ADD30|        6473.62|         US Dollar|    6473.62|       US Dollar|  Reinvestment|            0|2022-09-01 00:24:00|\n",
            "|       11|800059120|   1217|8006AD4E0|        60562.0|         US Dollar|    60562.0|       US Dollar|           ACH|            0|2022-09-01 00:17:00|\n",
            "|       11|8000ECA90|     11|8000ECA90|          22.97|         US Dollar|      22.97|       US Dollar|  Reinvestment|            0|2022-09-01 00:07:00|\n",
            "|     1120|8006AA910| 243166|81470DCF0|          43.53|         US Dollar|      43.53|       US Dollar|   Credit Card|            0|2022-09-01 00:28:00|\n",
            "|     1217|8006AD4E0|   1217|8006AD4E0|           5.04|         US Dollar|       5.04|       US Dollar|  Reinvestment|            0|2022-09-01 00:22:00|\n",
            "|      224|8006AD580|  23319|80567ED00|           9.28|         US Dollar|       9.28|       US Dollar|   Credit Card|            0|2022-09-01 00:28:00|\n",
            "|      394|8006AF210| 214342|805586EA0|          93.85|         US Dollar|      93.85|       US Dollar|   Credit Card|            0|2022-09-01 00:28:00|\n",
            "|     3618|800929EA0|   1277|800929EF0|           0.05|         US Dollar|       0.05|       US Dollar|           ACH|            0|2022-09-01 00:29:00|\n",
            "|      394|80093BDB0|  21414|80092A6C0|        64335.0|         US Dollar|    64335.0|       US Dollar|           ACH|            0|2022-09-01 00:08:00|\n",
            "|     1291|80092A730|   1291|80092A730|        3975.24|         US Dollar|    3975.24|       US Dollar|  Reinvestment|            0|2022-09-01 00:04:00|\n",
            "|     1231|800B69730|  11265|80092AC50|         1986.0|         US Dollar|     1986.0|       US Dollar|        Cheque|            0|2022-09-01 00:20:00|\n",
            "|      394|80093BDB0|    394|80093BDB0|       14903.78|         US Dollar|   14903.78|       US Dollar|  Reinvestment|            0|2022-09-01 00:14:00|\n",
            "|     1231|800B69730|  21414|80093CED0|          217.0|         US Dollar|      217.0|       US Dollar|           ACH|            0|2022-09-01 00:23:00|\n",
            "|       20|800952940|     20|800952940|       21126.92|         US Dollar|   21126.92|       US Dollar|  Reinvestment|            0|2022-09-01 00:05:00|\n",
            "|    31811|800A8FCD0|  31811|800A8FCD0|        4455.63|         US Dollar|    4455.63|       US Dollar|  Reinvestment|            0|2022-09-01 00:03:00|\n",
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "li_small_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pXkRYcZkRjl"
      },
      "source": [
        "### Exploratory Data Analysis\n",
        "---\n",
        "\n",
        "For simplicity and time saving we will analyse only the LI Datasets\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "\n",
        "* Reinvestment doesn't appear to have money laundry\n",
        "* Laundering occur in self transactions in few cases\n",
        "* Accounts are identifiers of the transaction\n",
        "* There is no money laundring happening in between currencies. Which mean we can keep only one variable for Receiving Currency and Payment Currency, and Amount Received and Amount Paid\n",
        "\n",
        "\n",
        "**Possible Features:**\n",
        "\n",
        "* Self Transaction flag\n",
        "* Time of the day transaction (morning, afternoon, night, dawn)\n",
        "* Day of the month transaction?\n",
        "* Month of the transaction?\n",
        "* Number of transactions in the day\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a88Hk22NlBip"
      },
      "outputs": [],
      "source": [
        "small_df = li_small_df\n",
        "large_df = li_large_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV7hb81EQA7Q"
      },
      "source": [
        "#### Small Dataset Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I6abj9ukdPq",
        "outputId": "37cb90b5-0418-48b5-f0ff-f5d4bf3f7de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-------+\n",
            "|Is Laundering|  count|\n",
            "+-------------+-------+\n",
            "|            1|   3565|\n",
            "|            0|6920484|\n",
            "+-------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the label distribution in the dataset\n",
        "small_df.groupBy(\"Is Laundering\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVclrJ2RQPFL",
        "outputId": "bce4e906-eae1-4720-e474-c3bb7196ea26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|summary|     Amount Received|         Amount Paid|\n",
            "+-------+--------------------+--------------------+\n",
            "|  count|                3565|                3565|\n",
            "|   mean|  3626202.3871408654|  3626202.3871408654|\n",
            "| stddev|6.2200284356123395E7|6.2200284356123395E7|\n",
            "|    min|            0.001136|            0.001136|\n",
            "|    max|        2.47329536E9|        2.47329536E9|\n",
            "+-------+--------------------+--------------------+\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|summary|     Amount Received|         Amount Paid|\n",
            "+-------+--------------------+--------------------+\n",
            "|  count|             6920484|             6920484|\n",
            "|   mean|  6325456.3603514815|  4676576.7705724845|\n",
            "| stddev|2.1059128350347283E9|1.5444954950918577E9|\n",
            "|    min|              1.0E-6|              1.0E-6|\n",
            "|    max|       3.64485358E12|       3.64485358E12|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into Legit and Laundering Transactions to analyze the feature in each case\n",
        "small_laundering_df = small_df.filter(small_df[\"Is Laundering\"] == 1)\n",
        "small_legit_df = small_df.filter(small_df[\"Is Laundering\"] == 0)\n",
        "\n",
        "float_columns = [\"Amount Received\", \"Amount Paid\"]\n",
        "small_laundering_df.select(float_columns).describe().show()\n",
        "small_legit_df.select(float_columns).describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOnyisMrSVUf",
        "outputId": "61406f9a-da3a-4f09-a45a-d6c0f1802eb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2382"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distinct Ilegal Accounts\n",
        "small_laundering_df.select(countDistinct(\"Account2\")).first()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHhLwAONTjpf",
        "outputId": "e0f24fda-d7ca-487b-f725-6adfa0f6274a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----+\n",
            "|Payment Format|count|\n",
            "+--------------+-----+\n",
            "|   Credit Card|  261|\n",
            "|           ACH| 2611|\n",
            "|          Cash|  124|\n",
            "|       Bitcoin|  110|\n",
            "|        Cheque|  459|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Analysis of Ilegality through payment formats\n",
        "small_laundering_df.groupBy(\"Payment Format\").count().show()\n",
        "small_legit_df.groupBy(\"Payment Format\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u1jvyqIwX6hK",
        "outputId": "3127a3af-a9f8-4c1c-e61b-97204a397a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|     null|      115|81522E390|    115|81522E390|       40877.23|            Shekel|   40877.23|          Shekel|           ACH|            1|\n",
            "|     null|    13354|802E1FDA0|  13354|802E1FDA0|        3038.63|         US Dollar|    3038.63|       US Dollar|           ACH|            1|\n",
            "|     null|    25788|8026EA1A0|  25788|8026EA1A0|        4418.15|              Euro|    4418.15|            Euro|           ACH|            1|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show ilegal transactions are made for the same account\n",
        "small_laundering_df.filter(small_laundering_df[\"Account2\"] == small_laundering_df[\"Account4\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hCiHi0hOioaU",
        "outputId": "364172b9-699d-40b1-db5e-d76ea2d2e5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank|Account2|To Bank|Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show ilegal transactions difference in payment ammount\n",
        "small_laundering_df.filter(small_laundering_df[\"Amount Paid\"] != small_laundering_df[\"Amount Received\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCFYRL4MZuPM",
        "outputId": "5631358f-dffc-450e-8a27-14eebce6aa8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank|Account2|To Bank|Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "+---------+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show ilegal transactions in different currencies\n",
        "small_laundering_df.filter(small_laundering_df[\"Receiving Currency\"] != small_laundering_df[\"Payment Currency\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Marzpf3jMPK",
        "outputId": "d5febe87-6532-4291-88b0-aa6c1f0626f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-----+\n",
            "|Receiving Currency|count|\n",
            "+------------------+-----+\n",
            "|         US Dollar| 1456|\n",
            "|              Euro| 1025|\n",
            "|              Yuan|  189|\n",
            "|       Brazil Real|   72|\n",
            "|   Canadian Dollar|   86|\n",
            "|       Saudi Riyal|  115|\n",
            "| Australian Dollar|   77|\n",
            "|             Rupee|  112|\n",
            "|      Mexican Peso|   37|\n",
            "|             Ruble|   39|\n",
            "|          UK Pound|   40|\n",
            "|               Yen|   86|\n",
            "|           Bitcoin|  110|\n",
            "|       Swiss Franc|   56|\n",
            "|            Shekel|   65|\n",
            "+------------------+-----+\n",
            "\n",
            "+-----------------+-----+\n",
            "| Payment Currency|count|\n",
            "+-----------------+-----+\n",
            "|        US Dollar| 1456|\n",
            "|             Euro| 1025|\n",
            "|             Yuan|  189|\n",
            "|      Brazil Real|   72|\n",
            "|  Canadian Dollar|   86|\n",
            "|      Saudi Riyal|  115|\n",
            "|Australian Dollar|   77|\n",
            "|            Rupee|  112|\n",
            "|     Mexican Peso|   37|\n",
            "|            Ruble|   39|\n",
            "|         UK Pound|   40|\n",
            "|              Yen|   86|\n",
            "|          Bitcoin|  110|\n",
            "|      Swiss Franc|   56|\n",
            "|           Shekel|   65|\n",
            "+-----------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "small_laundering_df.groupBy(\"Receiving Currency\").count().show()\n",
        "small_laundering_df.groupBy(\"Payment Currency\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsyFkP_12mM5"
      },
      "source": [
        "**Account-related analysis:**\n",
        "\n",
        "* Account activity: Unusually high transaction activity or a large number of accounts linked to a particular entity may indicate suspicious behavior.\n",
        "\n",
        "* Create features that capture the frequency and volume of transactions from both the \"From Account\" and \"To Account.\"\n",
        "* Including the account identifiers as features may introduce data leakage because the model can learn patterns specific to  accounts.\n",
        "* The destination bank appears to have strong predictive power in this case.\n",
        "* The destination accounts as well, it appears to be accounts never used before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi-uLNTp06b1",
        "outputId": "71df0864-bf6f-485e-f4fb-5f81340225c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|     null|       70|10042B6A8|     14|8000FEFD0|       33199.17|              Euro|   33199.17|            Euro|        Cheque|            0|\n",
            "|     null|       70|10042B6A8|     20|80011ABE0|       30999.19|              Euro|   30999.19|            Euro|        Cheque|            0|\n",
            "|     null|       70|10042B6A8|     20|8001AB3F0|        1445.39|              Euro|    1445.39|            Euro|        Cheque|            0|\n",
            "|     null|       70|10042B6A8|     20|8001AB3F0|         706.43|              Euro|     706.43|            Euro|   Credit Card|            0|\n",
            "|     null|       70|10042B6A8|     20|8001AB3F0|        1043.06|              Euro|    1043.06|            Euro|          Cash|            0|\n",
            "|     null|       70|10042B6A8|     11|800254EA0|       21293.75|              Euro|   21293.75|            Euro|        Cheque|            0|\n",
            "|     null|       70|10042B6A8|     11|800254EA0|       10859.21|              Euro|   10859.21|            Euro|   Credit Card|            0|\n",
            "|     null|       70|10042B6A8|     11|800254EA0|        2694.05|              Euro|    2694.05|            Euro|          Cash|            0|\n",
            "|     null|       70|10042B6A8|     14|800269C20|        1694.97|              Euro|    1694.97|            Euro|        Cheque|            0|\n",
            "|     null|       70|10042B6A8|     14|800269C20|       11133.38|              Euro|   11133.38|            Euro|   Credit Card|            0|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "small_legit_df.where(small_laundering_df[\"Account2\"] == \"10042B6A8\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEbjMMsylcm",
        "outputId": "ff81a5c3-65cc-4477-be69-6977ef81603e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|     null|       70|10042B6A8| 212854|806242CD0|       22478.74|              Euro|   22478.74|            Euro|          Cash|            1|\n",
            "|     null|       70|10042B6A8| 115332|806573660|      9626868.0|              Euro|  9626868.0|            Euro|          Cash|            1|\n",
            "|     null|       70|10042B6A8|  38920|80E95DAC0|         323.25|              Euro|     323.25|            Euro|   Credit Card|            1|\n",
            "|     null|       70|10042B6A8|  24643|801F02820|        3572.59|              Euro|    3572.59|            Euro|        Cheque|            1|\n",
            "|     null|       70|10042B6A8| 215505|805F99460|          61.74|              Euro|      61.74|            Euro|          Cash|            1|\n",
            "|     null|       70|10042B6A8| 224191|80AEDE4A0|       910433.2|              Euro|   910433.2|            Euro|          Cash|            1|\n",
            "|     null|       70|10042B6A8| 110851|80B2862D0|          49.19|              Euro|      49.19|            Euro|        Cheque|            1|\n",
            "|     null|       70|10042B6A8|  24562|816325220|         328.61|              Euro|     328.61|            Euro|        Cheque|            1|\n",
            "|     null|       70|10042B6A8|    425|8041E5A30|       15496.46|              Euro|   15496.46|            Euro|          Cash|            1|\n",
            "|     null|       70|10042B6A8|   1768|8007D19B0|          12.06|              Euro|      12.06|            Euro|        Cheque|            1|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "small_laundering_df.where(small_laundering_df[\"Account2\"] == \"10042B6A8\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xtvkuDoqswr",
        "outputId": "8f156ccc-b2fa-4af1-e4ee-a689cb93eea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|Timestamp|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "|     null|      425|8041E5A30|   6681|8041E59E0|        2336.89|              Euro|    2336.89|            Euro|           ACH|            1|\n",
            "+---------+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "receinving_accs = [\"806242CD0\", \"806573660\", \"80E95DAC0\", \"801F02820\", \"805F99460\",\n",
        "                   \"80AEDE4A0\", \"80B2862D0\", \"816325220\", \"8041E5A30\", \"8007D19B0\"]\n",
        "small_laundering_df.where(small_laundering_df[\"Account2\"].isin(receinving_accs)).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckKIBz0yA_v"
      },
      "source": [
        "**Time-related analysis:**\n",
        "\n",
        "* Extract day of the week: Convert the timestamp into a day of the week feature. Illegal transactions may exhibit certain patterns or anomalies depending on the day of the week.\n",
        "\n",
        "* Extract hour of the day: Convert the timestamp into an hour of the day feature. Similar to the day of the week, certain hours may be more associated with illegal activities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9SOGr_OzIID",
        "outputId": "737999ef-a53f-43cc-8f1a-aaa35917eae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+-------+---------------+\n",
            "|  Weekday|count| count2|Laundering Rate|\n",
            "+---------+-----+-------+---------------+\n",
            "|   Sunday|  338| 282215|   0.0011976684|\n",
            "| Saturday|  595| 565611|   0.0010519597|\n",
            "|  Tuesday|  409| 656809|   0.0006227077|\n",
            "|   Monday|  397| 657048|   0.0006042177|\n",
            "|Wednesday|  386| 658149|   0.0005864933|\n",
            "|   Friday|  722|1918616|   0.0003763129|\n",
            "| Thursday|  718|2182036|   0.0003290505|\n",
            "+---------+-----+-------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "weekly_laundering = small_laundering_df.withColumn(\"Weekday\", date_format('Timestamp', 'EEEE')).groupBy(\"Weekday\").count().cache()\n",
        "weekly_legit = small_legit_df.withColumn(\"Weekday\", date_format('Timestamp', 'EEEE')).groupBy(\"Weekday\").count().cache()\n",
        "weekly_laundering.join(weekly_legit.withColumnRenamed(\"count\", \"count2\"), \"Weekday\"). \\\n",
        "                 withColumn(\"Laundering Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Laundering Rate\", col(\"Laundering Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Laundering Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRWhQpDS8sQe",
        "outputId": "59e708d7-2787-4308-82c6-ff5aa1264655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+------+------------+\n",
            "|Hour|count|count2| Hourly Rate|\n",
            "+----+-----+------+------------+\n",
            "|  13|  185|263201|0.0007028849|\n",
            "|  12|  183|262527|0.0006970712|\n",
            "|  14|  177|262009|0.0006755493|\n",
            "|  11|  176|262219|0.0006711947|\n",
            "|  16|  176|264201|0.0006661595|\n",
            "|  15|  174|262644|0.0006624937|\n",
            "|  19|  165|264212|0.0006244985|\n",
            "|  10|  163|263988|0.0006174523|\n",
            "|  18|  160|263955|0.0006061639|\n",
            "|   8|  153|262004|0.0005839606|\n",
            "|  20|  150|262244|0.0005719864|\n",
            "|   9|  149|262845|0.0005668740|\n",
            "|   7|  147|262048|0.0005609659|\n",
            "|   3|  143|263777|0.0005421246|\n",
            "|  17|  142|263004|0.0005399157|\n",
            "|   2|  134|261563|0.0005123049|\n",
            "|   5|  133|263235|0.0005052520|\n",
            "|  21|  133|264370|0.0005030828|\n",
            "|   4|  127|262450|0.0004839017|\n",
            "|  22|  122|263647|0.0004627400|\n",
            "+----+-----+------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hourly_laundering = small_laundering_df.withColumn(\"Hour\", hour('Timestamp')).groupBy(\"Hour\").count().cache()\n",
        "hourly_legit = small_legit_df.withColumn(\"Hour\", hour('Timestamp')).groupBy(\"Hour\").count().cache()\n",
        "hourly_laundering.join(hourly_legit.withColumnRenamed(\"count\", \"count2\"), \"Hour\"). \\\n",
        "                 withColumn(\"Hourly Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Hourly Rate\", col(\"Hourly Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Hourly Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgC03NMC90B-",
        "outputId": "2ccf4aba-f256-419d-d6f2-150fd3a1a60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+-------+------------+\n",
            "|Date|count| count2|  Daily Rate|\n",
            "+----+-----+-------+------------+\n",
            "|  16|    5|      2|2.5000000000|\n",
            "|  15|    6|      3|2.0000000000|\n",
            "|  17|    2|      1|2.0000000000|\n",
            "|  11|   47|     30|1.5666666667|\n",
            "|  13|   29|     19|1.5263157895|\n",
            "|  14|   18|     13|1.3846153846|\n",
            "|  12|   27|     21|1.2857142857|\n",
            "|  10|  301| 282576|0.0010652002|\n",
            "|   3|  292| 283034|0.0010316782|\n",
            "|   4|  291| 282185|0.0010312384|\n",
            "|   8|  402| 657536|0.0006113734|\n",
            "|   6|  380| 656790|0.0005785715|\n",
            "|   5|  370| 657027|0.0005631428|\n",
            "|   7|  368| 658136|0.0005591549|\n",
            "|   9|  367| 891206|0.0004118015|\n",
            "|   2|  350|1027408|0.0003406631|\n",
            "|   1|  310|1524497|0.0002033458|\n",
            "+----+-----+-------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "daily_laundering = small_laundering_df.withColumn(\"Date\", dayofmonth('Timestamp')).groupBy(\"Date\").count().cache()\n",
        "daily_legit = small_legit_df.withColumn(\"Date\", dayofmonth('Timestamp')).groupBy(\"Date\").count().cache()\n",
        "daily_laundering.join(daily_legit.withColumnRenamed(\"count\", \"count2\"), \"Date\"). \\\n",
        "                 withColumn(\"Daily Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Daily Rate\", col(\"Daily Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Daily Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s9Lj9SJCS5m",
        "outputId": "a58fe1b9-b0b4-4c11-fc68-39a7289bd5c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+\n",
            "|      Date|  count|\n",
            "+----------+-------+\n",
            "|2022-09-02|1027758|\n",
            "|2022-09-06| 657170|\n",
            "|2022-09-04| 282476|\n",
            "|2022-09-05| 657397|\n",
            "|2022-09-03| 283326|\n",
            "|2022-09-01|1524807|\n",
            "|2022-09-10| 282877|\n",
            "|2022-09-07| 658504|\n",
            "|2022-09-09| 891573|\n",
            "|2022-09-08| 657938|\n",
            "|2022-09-12|     48|\n",
            "|2022-09-11|     77|\n",
            "|2022-09-13|     48|\n",
            "|2022-09-15|      9|\n",
            "|2022-09-14|     31|\n",
            "|2022-09-17|      3|\n",
            "|2022-09-16|      7|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Isnt small simulation supposed to be 10 days?\n",
        "small_df.withColumn(\"Date\", to_date('Timestamp')).groupby(\"Date\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk3UPkzCDUDd",
        "outputId": "c62ab07b-3d42-4e53-b00d-611a07b2c8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "|From Bank| Account2|To Bank| Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|          Timestamp|\n",
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "|     1291|8001F2990|      1|8002BBDF0|        3419.89|         US Dollar|    3419.89|       US Dollar|           ACH|            1|2022-09-16 00:00:00|\n",
            "|     1291|8001F2990|     12|8001F8B00|        8515.97|         US Dollar|    8515.97|       US Dollar|           ACH|            1|2022-09-16 12:41:00|\n",
            "|       11|8001AB0D0|     20|801CD38E0|         693.55|              Euro|     693.55|            Euro|           ACH|            1|2022-09-16 06:54:00|\n",
            "|       11|8001AB0D0|     11|8001AB0D0|        6921.45|         US Dollar|    5906.76|            Euro|           ACH|            0|2022-09-16 12:10:00|\n",
            "|       11|8001AB0D0|  23319|8013FA900|        6921.45|         US Dollar|    6921.45|       US Dollar|           ACH|            1|2022-09-16 12:10:00|\n",
            "|       11|8001AB0D0|     11|8001AB0D0|       14709.16|         US Dollar|    12552.8|            Euro|           ACH|            0|2022-09-16 13:24:00|\n",
            "|       11|8001AB0D0|   1439|8011BC1F0|       14709.16|         US Dollar|   14709.16|       US Dollar|           ACH|            1|2022-09-16 13:24:00|\n",
            "+---------+---------+-------+---------+---------------+------------------+-----------+----------------+--------------+-------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Very odd\n",
        "small_df.where(to_date(col(\"Timestamp\")).cast(\"string\") == \"2022-09-16\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc_6TNHvQKot"
      },
      "source": [
        "#### Large Dataset Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFaAG2XmlTxc",
        "outputId": "7bec48ea-5c75-4bb3-ed32-8f9655d65f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------+\n",
            "|Is Laundering|    count|\n",
            "+-------------+---------+\n",
            "|            1|   100604|\n",
            "|            0|175965953|\n",
            "+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the label distribution in the dataset\n",
        "large_df.groupBy(\"Is Laundering\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT4EyGYON65z",
        "outputId": "eedad70f-91ba-423a-8b79-53482255a312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|summary|     Amount Received|         Amount Paid|\n",
            "+-------+--------------------+--------------------+\n",
            "|  count|              100604|              100604|\n",
            "|   mean|5.7111282719604835E7|5.7111282719604835E7|\n",
            "| stddev|3.7370226655451694E9|3.7370226655451694E9|\n",
            "|    min|             2.81E-4|             2.81E-4|\n",
            "|    max|        6.2154002E11|        6.2154002E11|\n",
            "+-------+--------------------+--------------------+\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|summary|     Amount Received|         Amount Paid|\n",
            "+-------+--------------------+--------------------+\n",
            "|  count|           175965953|           175965953|\n",
            "|   mean|   7238086.466158445|   4857038.847415218|\n",
            "| stddev|1.7038381685874453E9|1.2869724486626391E9|\n",
            "|    min|              1.0E-6|              1.0E-6|\n",
            "|    max|        4.8345818E12|        4.8345818E12|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into Legit and Laundering Transactions to analyze the feature in each case\n",
        "large_laundering_df = large_df.filter(large_df[\"Is Laundering\"] == 1)\n",
        "large_legit_df = large_df.filter(large_df[\"Is Laundering\"] == 0)\n",
        "\n",
        "float_columns = [\"Amount Received\", \"Amount Paid\"]\n",
        "large_laundering_df.select(float_columns).describe().show()\n",
        "large_legit_df.select(float_columns).describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsBOoxRFUjS-",
        "outputId": "68527823-8c44-4de9-a1db-af5f64244fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60608"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distinct Ilegal Accounts\n",
        "large_laundering_df.select(countDistinct(\"Account2\")).first()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZOBArNrUzZK",
        "outputId": "65f970de-5593-4904-b028-7787a6efc50d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----+\n",
            "|Payment Format|count|\n",
            "+--------------+-----+\n",
            "|   Credit Card| 7554|\n",
            "|           ACH|75031|\n",
            "|          Cash| 3514|\n",
            "|       Bitcoin| 1499|\n",
            "|        Cheque|13003|\n",
            "|          Wire|    3|\n",
            "+--------------+-----+\n",
            "\n",
            "+--------------+--------+\n",
            "|Payment Format|   count|\n",
            "+--------------+--------+\n",
            "|   Credit Card|49904336|\n",
            "|           ACH|21492746|\n",
            "|          Cash|18037238|\n",
            "|          Wire| 6339914|\n",
            "|       Bitcoin| 3585151|\n",
            "|  Reinvestment| 7258238|\n",
            "|        Cheque|69348330|\n",
            "+--------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Analysis of Ilegality through payment formats\n",
        "large_laundering_df.groupBy(\"Payment Format\").count().show()\n",
        "large_legit_df.groupBy(\"Payment Format\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1XgxEZfYy4K",
        "outputId": "7edcbdf1-8f32-4b17-dfe7-ffb8c78ab800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count how many ilegal transactions are made for the same account\n",
        "large_laundering_df.filter(large_laundering_df[\"Account2\"] == large_laundering_df[\"Account4\"]).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4uS3nNreba9"
      },
      "outputs": [],
      "source": [
        "large_laundering_df.filter(large_laundering_df[\"Amount Paid\"] != large_laundering_df[\"Amount Received\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kjofzeCrc_Oc",
        "outputId": "2f46efa0-0a75-4155-bc2d-8fbddba36c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+---------+\n",
            "|From Bank|Account2|To Bank|Account4|Amount Received|Receiving Currency|Amount Paid|Payment Currency|Payment Format|Is Laundering|Timestamp|\n",
            "+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+---------+\n",
            "+---------+--------+-------+--------+---------------+------------------+-----------+----------------+--------------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show ilegal transactions in different currencies\n",
        "large_laundering_df.filter(large_laundering_df[\"Receiving Currency\"] != large_laundering_df[\"Payment Currency\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iZAfyxYgkmnV",
        "outputId": "1209802a-16f5-40b2-c295-9b7fed5ac6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-----+\n",
            "|Receiving Currency|count|\n",
            "+------------------+-----+\n",
            "|         US Dollar|38346|\n",
            "|              Euro|26022|\n",
            "|              Yuan| 5597|\n",
            "|       Brazil Real| 2265|\n",
            "|   Canadian Dollar| 3178|\n",
            "|             Rupee| 3896|\n",
            "| Australian Dollar| 2764|\n",
            "|       Saudi Riyal| 1662|\n",
            "|             Ruble| 2906|\n",
            "|               Yen| 3363|\n",
            "|          UK Pound| 2960|\n",
            "|           Bitcoin| 1499|\n",
            "|       Swiss Franc| 2532|\n",
            "|      Mexican Peso| 1774|\n",
            "|            Shekel| 1840|\n",
            "+------------------+-----+\n",
            "\n",
            "+-----------------+-----+\n",
            "| Payment Currency|count|\n",
            "+-----------------+-----+\n",
            "|        US Dollar|38346|\n",
            "|             Euro|26022|\n",
            "|             Yuan| 5597|\n",
            "|      Brazil Real| 2265|\n",
            "|  Canadian Dollar| 3178|\n",
            "|            Rupee| 3896|\n",
            "|Australian Dollar| 2764|\n",
            "|      Saudi Riyal| 1662|\n",
            "|            Ruble| 2906|\n",
            "|              Yen| 3363|\n",
            "|         UK Pound| 2960|\n",
            "|          Bitcoin| 1499|\n",
            "|      Swiss Franc| 2532|\n",
            "|     Mexican Peso| 1774|\n",
            "|           Shekel| 1840|\n",
            "+-----------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "large_laundering_df.groupBy(\"Receiving Currency\").count().show()\n",
        "large_laundering_df.groupBy(\"Payment Currency\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-QI1eIgEOwH"
      },
      "source": [
        "**Time-related analysis:**\n",
        "\n",
        "* Extract day of the week: Convert the timestamp into a day of the week feature. Illegal transactions may exhibit certain patterns or anomalies depending on the day of the week.\n",
        "\n",
        "* Extract hour of the day: Convert the timestamp into an hour of the day feature. Similar to the day of the week, certain hours may be more associated with illegal activities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uqkkFBPEEOcW",
        "outputId": "c98f7fba-bf8e-4746-81c7-4ae041001914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+--------+---------------+\n",
            "|  Weekday|count|  count2|Laundering Rate|\n",
            "+---------+-----+--------+---------------+\n",
            "| Saturday|12796|11386828|   0.0011237546|\n",
            "|   Sunday|12051|12931953|   0.0009318778|\n",
            "| Thursday|14863|26463559|   0.0005616403|\n",
            "|  Tuesday|14787|26468510|   0.0005586639|\n",
            "|Wednesday|14903|28778723|   0.0005178479|\n",
            "|   Monday|14825|28965215|   0.0005118208|\n",
            "|   Friday|16379|40971165|   0.0003997690|\n",
            "+---------+-----+--------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "weekly_laundering = large_laundering_df.withColumn(\"Weekday\", date_format('Timestamp', 'EEEE')).groupBy(\"Weekday\").count().cache()\n",
        "weekly_legit = large_legit_df.withColumn(\"Weekday\", date_format('Timestamp', 'EEEE')).groupBy(\"Weekday\").count().cache()\n",
        "weekly_laundering.join(weekly_legit.withColumnRenamed(\"count\", \"count2\"), \"Weekday\"). \\\n",
        "                 withColumn(\"Laundering Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Laundering Rate\", col(\"Laundering Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Laundering Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TycaBhsbEUcN",
        "outputId": "01d4c10c-bcac-49f8-fa18-12d7f3861360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+-------+------------+\n",
            "|Hour|count| count2| Hourly Rate|\n",
            "+----+-----+-------+------------+\n",
            "|  12| 4846|6855024|0.0007069268|\n",
            "|  11| 4831|6851304|0.0007051212|\n",
            "|  16| 4835|6858909|0.0007049226|\n",
            "|  15| 4709|6854639|0.0006869800|\n",
            "|  13| 4698|6860037|0.0006848360|\n",
            "|  14| 4691|6856477|0.0006841706|\n",
            "|  18| 4386|6860614|0.0006393014|\n",
            "|  19| 4344|6857660|0.0006334522|\n",
            "|  17| 4279|6853010|0.0006243972|\n",
            "|  10| 4268|6848716|0.0006231825|\n",
            "|   8| 4237|6855684|0.0006180273|\n",
            "|   9| 4215|6851019|0.0006152369|\n",
            "|   5| 4128|6861127|0.0006016504|\n",
            "|   7| 4108|6856407|0.0005991476|\n",
            "|   6| 3979|6862286|0.0005798359|\n",
            "|   3| 3890|6861294|0.0005669485|\n",
            "|   2| 3850|6858052|0.0005613839|\n",
            "|   4| 3816|6852737|0.0005568578|\n",
            "|   1| 3801|6870525|0.0005532328|\n",
            "|  22| 3719|6851093|0.0005428331|\n",
            "+----+-----+-------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hourly_laundering = large_laundering_df.withColumn(\"Hour\", hour('Timestamp')).groupBy(\"Hour\").count().cache()\n",
        "hourly_legit = large_legit_df.withColumn(\"Hour\", hour('Timestamp')).groupBy(\"Hour\").count().cache()\n",
        "hourly_laundering.join(hourly_legit.withColumnRenamed(\"count\", \"count2\"), \"Hour\"). \\\n",
        "                 withColumn(\"Hourly Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Hourly Rate\", col(\"Hourly Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Hourly Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ex_E1ug0EUtX",
        "outputId": "2449aa30-8c3f-4806-b751-5c07f83978ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+-------+------------+\n",
            "|Date|count| count2|  Daily Rate|\n",
            "+----+-----+-------+------------+\n",
            "|  25| 3190|4594404|0.0006943229|\n",
            "|  20| 3143|4594374|0.0006840976|\n",
            "|  29| 3143|4596368|0.0006838008|\n",
            "|  27| 3089|4590902|0.0006728525|\n",
            "|  18| 3084|4592763|0.0006714912|\n",
            "|  22| 3076|4596914|0.0006691446|\n",
            "|   8| 3059|4595246|0.0006656880|\n",
            "|  15| 3050|4594305|0.0006638654|\n",
            "|  11| 3037|4592294|0.0006613253|\n",
            "|  24| 3026|4592248|0.0006589365|\n",
            "|  17| 3005|4593527|0.0006541814|\n",
            "|   6| 2993|4594398|0.0006514455|\n",
            "|  13| 2965|4594941|0.0006452749|\n",
            "|  10| 2944|4592106|0.0006411002|\n",
            "|  23| 3178|5271296|0.0006028878|\n",
            "|   9| 3167|5271940|0.0006007276|\n",
            "|   3| 3861|6484799|0.0005953924|\n",
            "|  21| 3086|5272882|0.0005852587|\n",
            "|  28| 3288|5654568|0.0005814768|\n",
            "|   7| 3004|5272204|0.0005697807|\n",
            "+----+-----+-------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "daily_laundering = large_laundering_df.withColumn(\"Date\", dayofmonth('Timestamp')).groupBy(\"Date\").count().cache()\n",
        "daily_legit = large_legit_df.withColumn(\"Date\", dayofmonth('Timestamp')).groupBy(\"Date\").count().cache()\n",
        "daily_laundering.join(daily_legit.withColumnRenamed(\"count\", \"count2\"), \"Date\"). \\\n",
        "                 withColumn(\"Daily Rate\", col(\"count\") / col(\"count2\")). \\\n",
        "                 withColumn(\"Daily Rate\", col(\"Daily Rate\").cast('Decimal(20,10)')). \\\n",
        "                 orderBy(col(\"Daily Rate\").desc()). \\\n",
        "                 show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uin1y6rgK3_"
      },
      "source": [
        "## Feature Data\n",
        "\n",
        "\n",
        "The feature data layer comprises an analytics-specific data model that includes a collection of features defined based on the primary data. In practical terms, this layer represents both the independent variables and the target variable, which serve as the foundation for exploring and applying machine learning techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g2f4zQyuHA0"
      },
      "outputs": [],
      "source": [
        "def remove_node():\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzxks-7CuLzP"
      },
      "outputs": [],
      "source": [
        "def pipeline(data):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb2sybU5POQ_"
      },
      "source": [
        "# 1. Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4obs6eWu1XY"
      },
      "source": [
        "## Iris Dataset\n",
        "\n",
        "Even though the objective of the project is to classify the transactions in the IBM Transactions for Anti Money Laundering dataset, a good approach into developing a machine learning algorithm from scratch it to start developing it in a well controlled environment. Therefore, this project will use the Iris dataset to guide the development of a decision tree. This decision allow us to evaluate the implementation of the model in a common dataset which we know that the decision tree should perfom well. Therefore serving as a baseline and sanity check of the model implementation.\n",
        "\n",
        "The Iris dataset is a traditional dataset used in the machine learning domain to evaluate models. It consists of 3 different types of irises' (Setosa, Versicolour, and Virginica) stored in a 150x4 numpy array. Every type of iris has exactly 50 samples, thus being a well balanced dataset. However, we will constuct a tree focused on binary classification and not multiclass classification, and to do such we remve on the types on the data. The data set data is shown bellow:\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Iris_dataset_scatterplot.svg\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "> *Image courtesy of [wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set)*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggLC_j4Otu8A"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dW3E8kB1bmx",
        "outputId": "abf3daa4-e101-46e2-c44e-60eb44f7ccd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ],
      "source": [
        "print(iris['DESCR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EJ6I8zs6uyMo",
        "outputId": "66f56e84-0318-4dd3-c9fd-9c36f02e7bd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1698ef7a-e2ff-480e-9b71-4240128e130a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1698ef7a-e2ff-480e-9b71-4240128e130a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1698ef7a-e2ff-480e-9b71-4240128e130a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1698ef7a-e2ff-480e-9b71-4240128e130a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                  5.1               3.5                1.4               0.2   \n",
              "1                  4.9               3.0                1.4               0.2   \n",
              "2                  4.7               3.2                1.3               0.2   \n",
              "3                  4.6               3.1                1.5               0.2   \n",
              "4                  5.0               3.6                1.4               0.2   \n",
              "..                 ...               ...                ...               ...   \n",
              "145                6.7               3.0                5.2               2.3   \n",
              "146                6.3               2.5                5.0               1.9   \n",
              "147                6.5               3.0                5.2               2.0   \n",
              "148                6.2               3.4                5.4               2.3   \n",
              "149                5.9               3.0                5.1               1.8   \n",
              "\n",
              "     target  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "..      ...  \n",
              "145       2  \n",
              "146       2  \n",
              "147       2  \n",
              "148       2  \n",
              "149       2  \n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "iris_df.target = iris_df.target.astype('int')\n",
        "iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2oIJV80z9N1"
      },
      "source": [
        "We will split the dataset into two. The first dataset will have the setosa and the versicolor while the second will have the versicolor and virginica. From the data visualization image the former dataset will be linear separable in multiple thus being easier to classify, while the latter is not linear separable thus probabliy more difficult.\n",
        "\n",
        "- 0 = setosa\n",
        "- 1 = versicolor\n",
        "- 2 = virginica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZk168Qo0tGg"
      },
      "outputs": [],
      "source": [
        "def split_test_val(data, label_col, val_rate = 0.3):\n",
        "  data = data.sample(frac = 1).reset_index(drop=True)\n",
        "  split_index = round(len(data)*(1-val_rate))\n",
        "  data_train = data[:split_index]\n",
        "  data_val = data[split_index:]\n",
        "\n",
        "  train_X = data_train.drop(labels=label_col, axis=1)\n",
        "  train_y = data_train[label_col]\n",
        "\n",
        "\n",
        "  val_X = data_val.drop(labels=label_col, axis=1)\n",
        "  val_y = data_val[label_col]\n",
        "\n",
        "  return train_X, train_y, val_X, val_y\n",
        "\n",
        "iris_easy = iris_df.loc[(iris_df.target == 0 )| (iris_df.target == 1)]\n",
        "iris_hard = iris_df.loc[(iris_df.target == 1 )| (iris_df.target == 2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PauYUQMy30rn"
      },
      "source": [
        "## The Tree Structure\n",
        "\n",
        "A tree predictor has the structure of an ordered and rooted tree where each node is either a leaf (if it has zero children) or an internal node (if it has at least two children).\n",
        "\n",
        "The predictior is usualy defined by a tree T whose internal nodes are tagged with tests and leaves are tagged with labels. A test in an internal node with a funtion over an atribute of the dataset with separate the data into multiple subsets. Since we are implementing a binary tree this function will only split into two subsets.\n",
        "\n",
        "Therefore, the primary structure of the tree is a node, which might be internal (having a attribute and a test) or a leaf (having a label). For simplicity we build a generic node which can be adapted for whichever case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v9hdTsPs1-A"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "\n",
        "    def __init__(self, label=None, attribute=None, split_test=None):\n",
        "        self.label = label\n",
        "        self.attribute = attribute\n",
        "        self.split_test = split_test\n",
        "        self.is_leaf = True\n",
        "        self.left_child = None\n",
        "        self.right_child = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5lgECrS75UY"
      },
      "source": [
        "## Building a Binary Tree\n",
        "\n",
        "We focus on the case of binary trees (all internal nodes have exacly two children) for binary classification. The main idea of building the tree is growing it starting from a single node tree (which is a leaf) that corresponds to the classifier assigning to any data point the label that occurs most frequently in the traning set. The tree is grown by picking a leaf and replacing it with an internal node and two new leaves.\n",
        "\n",
        "However this description of a binary tree leaves some questions open. How do we select an attribute? How do we select the best threshold to split this attribute? How do we select a node to grow? When do we stop growing the tree? How do we calculate the training error?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x10C6WFvmhGZ"
      },
      "source": [
        "### Calculating the Training Error\n",
        "\n",
        "One step of the tree building process is measuring the error of the constructed tree. Suppose we have grown a tree up to a certain point and built a classifier. We consider the training error as the sum of the contributions of all leaves in the tree.\n",
        "\n",
        "When a leaf does not contribute to the training error, we say that that leaf is pure. On the other hand leaves that does contribute are impure and thus we focus on measuring the impurity of the tree (the entropy). Additionally, the decision tree may also suffer from overfitting, that usually happens when the tree overgrows the cardinality of the training set. Therefore its important to choose the leaf expension guaranteeing the largest decrease in the training error. Thus making a well informed decision such that the error decreases the largest with the least ammount of growth.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXsSz_sDmO2B"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(labels, func_type):\n",
        "  # Get counts of zero and ones as vector\n",
        "  _, counts = np.unique(labels, return_counts=True)\n",
        "  # Normalize\n",
        "  p_vec = counts / len(labels)\n",
        "\n",
        "  # Calculate proper entropy criterion\n",
        "  if func_type == 'shannon':\n",
        "    return -np.sum(p_vec * np.log2(p_vec))\n",
        "  elif func_type == 'scaled':\n",
        "    return -np.sum((p_vec/2) * np.log2(p_vec))\n",
        "  elif func_type == 'gini':\n",
        "    return 1 - np.sum(np.square(p_vec))\n",
        "\n",
        "def calculate_information_gain(data, labels, left_labels, right_labels, func_type):\n",
        "    total_entropy = calculate_entropy(labels, func_type)\n",
        "    left_entropy = calculate_entropy(left_labels, func_type)\n",
        "    right_entropy = calculate_entropy(right_labels, func_type)\n",
        "\n",
        "    left_weighted_entropy = (len(left_labels) / len(labels)) * left_entropy\n",
        "    right_weighted_entropy = (len(right_labels) / len(right_labels)) * right_entropy\n",
        "    information_gain = total_entropy - (left_weighted_entropy + right_weighted_entropy)\n",
        "    return information_gain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdcrC2zL-G6M"
      },
      "source": [
        "### Attribute and Threshold Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIIfJtl4mEnw"
      },
      "outputs": [],
      "source": [
        "def select_attribute(data, labels, func_type):\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    best_information_gain = -np.inf\n",
        "\n",
        "    for feature in data.columns:\n",
        "        # Get index of the column\n",
        "        col_idx = data.columns.get_loc(feature)\n",
        "        # Get possible values within this feature\n",
        "        feature_values = data.iloc[:, col_idx]\n",
        "        # Filter only the unique\n",
        "        unique_values = np.unique(feature_values)\n",
        "        # Get possible thresholds\n",
        "        thresholds = (unique_values[:-1] + unique_values[1:]) / 2.0\n",
        "\n",
        "        # Calculate info gain of each threshold\n",
        "        for threshold in thresholds:\n",
        "            # Get the possible labels for the left node\n",
        "            left_labels = labels[data.iloc[:, col_idx] <= threshold]\n",
        "\n",
        "            # Get the possible labels for the right node\n",
        "            right_labels = labels[data.iloc[:, col_idx] > threshold]\n",
        "             # labels[np.where(data.iloc[:, col_idx] > threshold)[0]]\n",
        "\n",
        "            # Calculate the information gain of the split\n",
        "            information_gain = calculate_information_gain(data, labels, left_labels, right_labels, func_type)\n",
        "\n",
        "            # Keep if best\n",
        "            if information_gain > best_information_gain:\n",
        "                best_feature = col_idx\n",
        "                best_threshold = threshold\n",
        "                best_information_gain = information_gain\n",
        "\n",
        "    return best_feature, best_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "r8GKnSoW9p4Y",
        "outputId": "af15786b-ff4b-4b46-cc0b-dbe8037313ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Feature: 3\n",
            "Best Threshold: 1.75\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f01b0e47310>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data, labels, _, _ = split_test_val(iris_hard, 'target', val_rate = 0.3)\n",
        "best_feature, best_treshold = select_attribute(data, labels, 'shannon')\n",
        "\n",
        "print(f\"Best Feature: {best_feature}\")\n",
        "print(f\"Best Threshold: {best_treshold}\")\n",
        "\n",
        "data[\"target\"] = labels\n",
        "\n",
        "sns.swarmplot(data=data, x=data.columns[best_feature], hue=\"target\")\n",
        "plt.axvline(x=best_treshold, color='grey')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dF0p8z1-fOU"
      },
      "source": [
        "### Stopping Criterias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO1YNTL0L10r"
      },
      "outputs": [],
      "source": [
        "def max_depth_stop(depth, max_depth):\n",
        "  return depth==max_depth\n",
        "\n",
        "def no_labels_to_split_stop(labels):\n",
        "  return len(np.unique(labels)) == 1\n",
        "\n",
        "def min_samples_split_stop(labels, min_samples_per_split):\n",
        "  return len(labels) < min_samples_per_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ontg1Ydh-DmJ"
      },
      "source": [
        "### Building the Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79EoP4ZKke9h"
      },
      "outputs": [],
      "source": [
        "def build_decision_tree(data, labels, depth=0, max_depth=10, min_samples_per_split=2, func_type='shannon'):\n",
        "    # Initialize an empty root node\n",
        "    node = Node()\n",
        "\n",
        "    if max_depth_stop(depth, max_depth) or no_labels_to_split_stop(labels) or min_samples_split_stop(labels, min_samples_per_split):\n",
        "        node.label = np.bincount(labels).argmax()\n",
        "        return node\n",
        "\n",
        "    # Attribute selection\n",
        "    best_feature, best_threshold = select_attribute(data, labels, func_type)\n",
        "    node.attribute = best_feature\n",
        "    node.split_test = best_threshold\n",
        "    node.is_leaf = False\n",
        "\n",
        "\n",
        "    # Split the data to create Sl' and Sl'' based on the selected attribute and threshold\n",
        "    left_indices = data.iloc[:, best_feature] <= best_threshold\n",
        "    right_indices = data.iloc[:, best_feature] > best_threshold\n",
        "\n",
        "    left_data, left_labels = data.loc[left_indices], labels.loc[left_indices]\n",
        "    right_data, right_labels = data.loc[right_indices], labels.loc[right_indices]\n",
        "\n",
        "    # Recursively build the left and right subtrees\n",
        "    if len(left_data) > 0:\n",
        "        node.left_child = build_decision_tree(left_data, left_labels, depth = depth+1,\n",
        "                                              max_depth=max_depth, min_samples_per_split=min_samples_per_split, func_type=func_type)\n",
        "    if len(right_data) > 0:\n",
        "        node.right_child = build_decision_tree(right_data, right_labels, depth = depth+1,\n",
        "                                               max_depth=max_depth, min_samples_per_split=min_samples_per_split, func_type=func_type)\n",
        "\n",
        "    return node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-ZfZj_um0-Z"
      },
      "outputs": [],
      "source": [
        "easy_train_X, easy_train_y, easy_test_X, easy_test_y = split_test_val(iris_easy, 'target', val_rate = 0.3)\n",
        "easy_tree = build_decision_tree(easy_train_X, easy_train_y, max_depth=1)\n",
        "\n",
        "hard_train_X, hard_train_y, hard_test_X, hard_test_y = split_test_val(iris_hard, 'target', val_rate = 0.3)\n",
        "hard_tree = build_decision_tree(hard_train_X, hard_train_y, max_depth=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwYtKI0mhr7"
      },
      "source": [
        "#### Viewing Iris Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBIRjiiJVWz8"
      },
      "outputs": [],
      "source": [
        "def print_decision_tree(node, columns, indent=\"\"):\n",
        "    if node.is_leaf:\n",
        "        print(indent + \"Label:\", node.label)\n",
        "        return\n",
        "\n",
        "    if not node.is_leaf:\n",
        "        print(indent + columns[node.attribute] + \" <= \" + str(node.split_test))\n",
        "\n",
        "    print(indent + \"Left:\")\n",
        "    print_decision_tree(node.left_child, columns, indent + \"  \")\n",
        "\n",
        "    print(indent + \"Right:\")\n",
        "    print_decision_tree(node.right_child, columns, indent + \"  \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8gDI7Z3O3I0",
        "outputId": "19491d76-9147-40e8-80c3-3a72377a02ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "petal length (cm) <= 2.45\n",
            "Left:\n",
            "  Label: 0\n",
            "Right:\n",
            "  Label: 1\n"
          ]
        }
      ],
      "source": [
        "print_decision_tree(easy_tree, easy_train_X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8SIAykvnHyf",
        "outputId": "138f06a0-c5c1-41cf-aa54-5e5ad91e5c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "petal length (cm) <= 5.05\n",
            "Left:\n",
            "  petal width (cm) <= 1.9\n",
            "  Left:\n",
            "    sepal length (cm) <= 6.35\n",
            "    Left:\n",
            "      sepal width (cm) <= 3.1\n",
            "      Left:\n",
            "        petal width (cm) <= 1.65\n",
            "        Left:\n",
            "          Label: 1\n",
            "        Right:\n",
            "          Label: 2\n",
            "      Right:\n",
            "        Label: 1\n",
            "    Right:\n",
            "      Label: 1\n",
            "  Right:\n",
            "    Label: 2\n",
            "Right:\n",
            "  Label: 2\n"
          ]
        }
      ],
      "source": [
        "print_decision_tree(hard_tree, hard_train_X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOCDdpo6jEnt"
      },
      "source": [
        "## Predict & Error in Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH0jlxhbjHtU"
      },
      "outputs": [],
      "source": [
        "def _predict_single(node, instance):\n",
        "    if node.label is not None:\n",
        "        return node.label\n",
        "\n",
        "    if instance[node.attribute] <= node.split_test:\n",
        "        return _predict_single(node.left_child, instance)\n",
        "    else:\n",
        "        return _predict_single(node.right_child, instance)\n",
        "\n",
        "def predict(root_node, data):\n",
        "  predictions = [_predict_single(root_node, instance[1]) for instance in data.iterrows()]\n",
        "  return predictions\n",
        "\n",
        "def calculate_error(predictions, labels):\n",
        "    wrong_predictions = np.sum(predictions != labels)\n",
        "    error = wrong_predictions / len(labels)\n",
        "    return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SCdYs6KjNFG",
        "outputId": "857ca5d9-2d41-4a05-a85a-cad01716b1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Separable IRIS Set: Training Error 0.0; Test Error: 0.0\n",
            "Non Linear Separable IRIS Set: Training Error 0.0; Test Error: 0.06666666666666667\n"
          ]
        }
      ],
      "source": [
        "easy_train_preds = predict(easy_tree, easy_train_X)\n",
        "easy_test_preds = predict(easy_tree, easy_test_X)\n",
        "error_easy_train = calculate_error(easy_train_preds, easy_train_y)\n",
        "error_easy_test = calculate_error(easy_test_preds, easy_test_y)\n",
        "\n",
        "hard_train_preds = predict(hard_tree, hard_train_X)\n",
        "hard_test_preds = predict(hard_tree, hard_test_X)\n",
        "error_hard_train = calculate_error(hard_train_preds, hard_train_y)\n",
        "error_hard_test = calculate_error(hard_test_preds, hard_test_y)\n",
        "\n",
        "print(f\"Linear Separable IRIS Set: Training Error {error_easy_train}; Test Error: {error_easy_test}\")\n",
        "print(f\"Non Linear Separable IRIS Set: Training Error {error_hard_train}; Test Error: {error_hard_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRiy02nBpBYe"
      },
      "source": [
        "## The DecisionTree Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUqLZp2UpAV3"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, label=None, attribute=None, split_test=None):\n",
        "        self.label = label\n",
        "        self.attribute = attribute\n",
        "        self.split_test = split_test\n",
        "        self.is_leaf = True\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "\n",
        "class DecisionTree:\n",
        "  def __init__(self, max_depth=10, min_samples_per_split=2, func_type='shannon'):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_per_split = min_samples_per_split\n",
        "    self.func_type = func_type\n",
        "    self.cols = None\n",
        "    self.root = None\n",
        "\n",
        "  def fit(self, data, label):\n",
        "    self.cols = data.columns\n",
        "    self.root = self._build_decision_tree(data, label)\n",
        "\n",
        "    predictions = self.predict(data)\n",
        "    wrong_predictions = np.sum(predictions != label)\n",
        "    error = wrong_predictions / len(label)\n",
        "    print(f\"Model fitted with training error: {error}\")\n",
        "\n",
        "    return self\n",
        "\n",
        "  def predict(self, data):\n",
        "    if not self.root:\n",
        "      raise NotImplementedError(\"Model not yet fitted.\")\n",
        "\n",
        "    predictions = [self._predict_single(self.root, instance[1]) for instance in data.iterrows()]\n",
        "    return predictions\n",
        "\n",
        "\n",
        "  def print_tree(self, node=None, indent=\"\"):\n",
        "      if not self.root:\n",
        "        raise NotImplementedError(\"Model not yet fitted.\")\n",
        "\n",
        "      if not node:\n",
        "        node = self.root\n",
        "\n",
        "      if node.is_leaf:\n",
        "          print(indent + \"Label:\", node.label)\n",
        "          return\n",
        "\n",
        "      if not node.is_leaf:\n",
        "          print(indent + self.cols[node.attribute] + \" <= \" + str(node.split_test))\n",
        "\n",
        "      print(indent + \"Left:\")\n",
        "      self.print_tree(node.left_child, indent + \"  \")\n",
        "\n",
        "      print(indent + \"Right:\")\n",
        "      self.print_tree(node.right_child, indent + \"  \")\n",
        "\n",
        "  def _calculate_entropy(self, labels):\n",
        "    # Get counts of zero and ones as vector\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    # Normalize\n",
        "    p_vec = counts / len(labels)\n",
        "\n",
        "    # Calculate proper entropy criterion\n",
        "    if self.func_type == 'shannon':\n",
        "      return -np.sum(p_vec * np.log2(p_vec))\n",
        "    elif self.func_type == 'scaled':\n",
        "      return -np.sum((p_vec/2) * np.log2(p_vec))\n",
        "    elif self.func_type == 'gini':\n",
        "      return 1 - np.sum(np.square(p_vec))\n",
        "\n",
        "  def _calculate_information_gain(self, data, labels, left_labels, right_labels):\n",
        "    total_entropy = self._calculate_entropy(labels)\n",
        "    left_entropy = self._calculate_entropy(left_labels)\n",
        "    right_entropy = self._calculate_entropy(right_labels)\n",
        "\n",
        "    left_weighted_entropy = (len(left_labels) / len(labels)) * left_entropy\n",
        "    right_weighted_entropy = (len(right_labels) / len(right_labels)) * right_entropy\n",
        "    information_gain = total_entropy - (left_weighted_entropy + right_weighted_entropy)\n",
        "    return information_gain\n",
        "\n",
        "  def _select_attribute(self, data, labels):\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    best_information_gain = -np.inf\n",
        "\n",
        "    for feature in data.columns:\n",
        "        # Get index of the column\n",
        "        col_idx = data.columns.get_loc(feature)\n",
        "        # Get possible values within this feature\n",
        "        feature_values = data.iloc[:, col_idx]\n",
        "        # Filter only the unique\n",
        "        unique_values = np.unique(feature_values)\n",
        "        # Get possible thresholds\n",
        "        thresholds = (unique_values[:-1] + unique_values[1:]) / 2.0\n",
        "\n",
        "        # Calculate info gain of each threshold\n",
        "        for threshold in thresholds:\n",
        "            # Get the possible labels for the left node\n",
        "            left_labels = labels[data.iloc[:, col_idx] <= threshold]\n",
        "\n",
        "            # Get the possible labels for the right node\n",
        "            right_labels = labels[data.iloc[:, col_idx] > threshold]\n",
        "            # labels[np.where(data.iloc[:, col_idx] > threshold)[0]]\n",
        "\n",
        "            # Calculate the information gain of the split\n",
        "            information_gain = self._calculate_information_gain(data, labels, left_labels, right_labels)\n",
        "\n",
        "            # Keep if best\n",
        "            if information_gain > best_information_gain:\n",
        "                best_feature = col_idx\n",
        "                best_threshold = threshold\n",
        "                best_information_gain = information_gain\n",
        "\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "  def _max_depth(self, depth):\n",
        "    return depth==self.max_depth\n",
        "\n",
        "  def _no_labels_to_split(self, labels):\n",
        "    return len(np.unique(labels)) == 1\n",
        "\n",
        "  def _min_samples_split(self, labels):\n",
        "    return len(labels) < self.min_samples_per_split\n",
        "\n",
        "  def _build_decision_tree(self, data, labels, depth=0):\n",
        "    # Initialize an empty root node\n",
        "    node = Node()\n",
        "\n",
        "    if self._max_depth(depth) or self._no_labels_to_split(labels) or self._min_samples_split(labels):\n",
        "        node.label = np.bincount(labels).argmax()\n",
        "        return node\n",
        "\n",
        "    # Attribute selection\n",
        "    best_feature, best_threshold = self._select_attribute(data, labels)\n",
        "    node.attribute = best_feature\n",
        "    node.split_test = best_threshold\n",
        "    node.is_leaf = False\n",
        "\n",
        "\n",
        "    # Split the data to create Sl' and Sl'' based on the selected attribute and threshold\n",
        "    left_indices = data.iloc[:, best_feature] <= best_threshold\n",
        "    right_indices = data.iloc[:, best_feature] > best_threshold\n",
        "\n",
        "    left_data, left_labels = data.loc[left_indices], labels.loc[left_indices]\n",
        "    right_data, right_labels = data.loc[right_indices], labels.loc[right_indices]\n",
        "\n",
        "    # Recursively build the left and right subtrees\n",
        "    if len(left_data) > 0:\n",
        "        node.left_child = self._build_decision_tree(left_data, left_labels, depth = depth+1)\n",
        "    if len(right_data) > 0:\n",
        "        node.right_child = self._build_decision_tree(right_data, right_labels, depth = depth+1)\n",
        "\n",
        "    return node\n",
        "\n",
        "  def _predict_single(self, node, instance):\n",
        "    if node.label is not None:\n",
        "        return node.label\n",
        "\n",
        "    if instance[node.attribute] <= node.split_test:\n",
        "        return self._predict_single(node.left_child, instance)\n",
        "    else:\n",
        "        return self._predict_single(node.right_child, instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YyQSujtvwpR",
        "outputId": "a383d554-2ba2-465f-c730-969cfde5d8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model fitted with training error: 0.0\n"
          ]
        }
      ],
      "source": [
        "hard_train_X, hard_train_y, hard_test_X, hard_test_y = split_test_val(iris_hard, 'target', val_rate = 0.3)\n",
        "clf = DecisionTree()\n",
        "clf = clf.fit(hard_train_X, hard_train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpYuRdTxwod1",
        "outputId": "558f634b-d107-4e7d-a20d-d60580fce25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "petal width (cm) <= 1.75\n",
            "Left:\n",
            "  petal length (cm) <= 5.35\n",
            "  Left:\n",
            "    sepal length (cm) <= 4.95\n",
            "    Left:\n",
            "      Label: 2\n",
            "    Right:\n",
            "      sepal width (cm) <= 2.8499999999999996\n",
            "      Left:\n",
            "        sepal length (cm) <= 6.4\n",
            "        Left:\n",
            "          petal width (cm) <= 1.55\n",
            "          Left:\n",
            "            petal length (cm) <= 4.95\n",
            "            Left:\n",
            "              Label: 1\n",
            "            Right:\n",
            "              Label: 2\n",
            "          Right:\n",
            "            Label: 1\n",
            "        Right:\n",
            "          Label: 1\n",
            "      Right:\n",
            "        Label: 1\n",
            "  Right:\n",
            "    Label: 2\n",
            "Right:\n",
            "  petal length (cm) <= 4.85\n",
            "  Left:\n",
            "    sepal length (cm) <= 6.050000000000001\n",
            "    Left:\n",
            "      Label: 1\n",
            "    Right:\n",
            "      Label: 2\n",
            "  Right:\n",
            "    Label: 2\n"
          ]
        }
      ],
      "source": [
        "clf.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1enFGlkOxtm5",
        "outputId": "4bb11bf9-e9e7-4c19-9279-2842073c6883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test error: 0.06666666666666667\n"
          ]
        }
      ],
      "source": [
        "def calculate_error(predictions, labels):\n",
        "    wrong_predictions = np.sum(predictions != labels)\n",
        "    error = wrong_predictions / len(labels)\n",
        "    return error\n",
        "\n",
        "test_preds = clf.predict(hard_test_X)\n",
        "test_error = calculate_error(test_preds, hard_test_y)\n",
        "print(f\"Test error: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QUtVFgDPVio"
      },
      "source": [
        "# 2. Distributed Workers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aPtD56WPoxV",
        "outputId": "87db7551-0a36-4bc8-941c-f6584ad2ece6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjt8N1-a7LzZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tb2sybU5POQ_",
        "F4obs6eWu1XY",
        "PauYUQMy30rn"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcXSpWDgj3AUrMeJD9NUUC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}